import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.probability import FreqDist
from heapq import nlargest
from collections import defaultdict
from string import punctuation


class ArticleSummarizer:
    def __init__(self):
        # Convert both to sets and use union operation
        self.stop_words = set(stopwords.words('english')).union(set(punctuation))
    
    def summarize(self, text, num_sentences=3):
        """
        Summarize the input text by extracting the most important sentences.
        
        Args:
            text (str): The input text to summarize
            num_sentences (int): Number of sentences to include in summary
            
        Returns:
            str: The generated summary
        """
        # Tokenize the text into sentences
        sentences = sent_tokenize(text)
        
        if not sentences:  # Handle empty text
            return "No meaningful content to summarize."
            
        # Tokenize words and remove stopwords
        words = word_tokenize(text.lower())
        words = [word for word in words if word not in self.stop_words and word.isalnum()]
        
        # Calculate word frequencies
        word_frequencies = FreqDist(words)
        
        # Calculate sentence scores based on word frequencies
        sentence_scores = defaultdict(int)
        for i, sentence in enumerate(sentences):
            for word in word_tokenize(sentence.lower()):
                if word in word_frequencies:
                    sentence_scores[i] += word_frequencies[word]
        
        # Get the top N sentences
        if not sentence_scores:  # Handle case where no words scored
            return " ".join(sentences[:num_sentences])
            
        top_sentence_indices = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)
        top_sentence_indices.sort()  # Maintain original order
        
        # Construct the summary
        summary = ' '.join([sentences[i] for i in top_sentence_indices])
        return summary

def main():
    print("=== Article Summarization Tool ===")
    print("Type 'exit' to quit at any time\n")
    
    summarizer = ArticleSummarizer()
    
    # Example usage
    sample_text = """
    Natural language processing (NLP) is a subfield of linguistics, computer science, 
    and artificial intelligence concerned with the interactions between computers and human language. 
    It focuses on how to program computers to process and analyze large amounts of natural language data. 
    The result is a computer capable of "understanding" the contents of documents, including the contextual 
    nuances of the language within them. The technology can then accurately extract information and insights 
    contained in the documents as well as categorize and organize the documents themselves.
    
    Challenges in natural language processing frequently involve speech recognition, natural language 
    understanding, and natural language generation. Modern NLP algorithms are based on machine learning, 
    especially statistical machine learning. The paradigm of machine learning is different from that of 
    most prior attempts at language processing. Prior implementations often involved direct hand-coding 
    of large sets of rules.
    
    NLP has many applications including machine translation, chatbots, sentiment analysis, and text 
    summarization. Text summarization is particularly useful for condensing long documents into shorter 
    versions while preserving key information. This helps readers quickly understand the main points 
    without reading the entire content.
    """
    
    print("=== Sample Summary ===")
    print(summarizer.summarize(sample_text))
    print("\n" + "="*50 + "\n")
    
    # Interactive mode
    while True:
        user_text = input("Enter text to summarize (min 10 words):\n> ")
        
        if user_text.lower() == 'exit':
            print("\nThank you for using the summarizer!")
            break
            
        word_count = len(user_text.split())
        if word_count < 10:
            print(f"Please enter at least 10 words (current: {word_count})")
            continue
            
        summary = summarizer.summarize(user_text)
        print("\n=== Summary ===")
        print(summary)
        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    main()
